{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69d20e1a-2870-4bdb-80de-7d6adefda421",
   "metadata": {},
   "source": [
    "# WEIGTHS AND DIMENTIONS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3aae1600-5818-47b5-8766-e15ac38e6f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias a usar\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, inspect, NVARCHAR, Float, Date, text\n",
    "from sqlalchemy import text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from prophet import Prophet\n",
    "from pmdarima import auto_arima\n",
    "from tqdm import tqdm \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, types\n",
    "import pyodbc\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from sqlalchemy import create_engine, Table, Column, MetaData, Integer, String, Float\n",
    "import os\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f763510a-392c-44a6-b9dd-9599714fb935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correo enviado correctamente\n"
     ]
    }
   ],
   "source": [
    "def send_email_inicio():\n",
    "    # Configuraci√≥n del correo\n",
    "    sender_email = \"ecalderon@maxwarehouse.com\"  \n",
    "    sender_password = \"Maxwarehouse2025$\"  \n",
    "\n",
    "    # üîπ Lista de destinatarios\n",
    "    recipient_list = [\"ecalderon@maxwarehouse.com\", \"vpverbena@maxwarehouse.com\"]\n",
    "    \n",
    "    # Contenido del correo\n",
    "    subject = \"üîî Alerta: Inicio de generaci√≥n de predicciones de pesos\"\n",
    "    body = \"El modelo de predicci√≥n ha empezado a correr.\"\n",
    "\n",
    "    # Crear el mensaje\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = \", \".join(recipient_list)\n",
    "\n",
    "    try:\n",
    "        # Conectar al servidor SMTP (ejemplo para Gmail)\n",
    "        server = smtplib.SMTP(\"smtp.office365.com\", 587)  # Usa \"smtp.office365.com\" para Outlook\n",
    "        server.starttls()  # Seguridad TLS\n",
    "        server.login(sender_email, sender_password)  # Autenticaci√≥n\n",
    "        server.sendmail(sender_email, recipient_list, msg.as_string())  # Enviar\n",
    "        server.quit()\n",
    "        print(\"‚úÖ Correo enviado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Error al enviar el correo: {e}\")\n",
    "\n",
    "# Llamar a la funci√≥n al final del proceso\n",
    "send_email_inicio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1380e2b0-0562-44f3-8935-7e2bd81f2451",
   "metadata": {},
   "source": [
    "## Incorporar reporte semanal de endicia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab00f8d1-a3f7-46ae-b311-f590e4e194e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo le√≠do: Account Transactional Activity.xlsx\n",
      "Datos de Account Transactional Activity.xlsx cargados exitosamente a SQL Server üéØ\n",
      "Archivo Account Transactional Activity.xlsx movido y renombrado a: C:\\Users\\ecalderon\\OneDrive - BITS - Max Warehouse\\Shipping\\Weights Process\\Reporte Semanal Endicia\\Procesados\\Account Transactional Activity_2025-05-06.xlsx\n"
     ]
    }
   ],
   "source": [
    "# --- Configuraci√≥n ---\n",
    "\n",
    "# Carpeta donde est√°n los archivos Excel\n",
    "carpeta = r'C:\\Users\\ecalderon\\OneDrive - BITS - Max Warehouse\\Shipping\\Weights Process\\Reporte Semanal Endicia'\n",
    "carpeta_destino = r'C:\\Users\\ecalderon\\OneDrive - BITS - Max Warehouse\\Shipping\\Weights Process\\Reporte Semanal Endicia\\Procesados'\n",
    "\n",
    "# Listar todos los archivos .xlsx de la carpeta\n",
    "excel_files = [f for f in os.listdir(carpeta) if f.endswith('.xlsx')]\n",
    "\n",
    "# Datos de conexi√≥n a SQL Server\n",
    "server = '10.12.200.59' \n",
    "database = 'Maxwarehouse'\n",
    "table_name = 'endicia_semanal'\n",
    "\n",
    "# sqlalchemy + pyodbc\n",
    "connection_string = f\"mssql+pyodbc://{server}/{database}?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Verificar si hay archivos para procesar\n",
    "if excel_files:\n",
    "    for excel_file in excel_files:\n",
    "        try:\n",
    "            # Ruta completa al archivo\n",
    "            ruta_archivo = os.path.join(carpeta, excel_file)\n",
    "\n",
    "            # Leer el archivo Excel\n",
    "            df = pd.read_excel(ruta_archivo)\n",
    "            print(f\"Archivo le√≠do: {excel_file}\")\n",
    "\n",
    "            # Cargar los datos a SQL Server\n",
    "            with engine.connect() as connection:\n",
    "                df.to_sql(table_name, con=connection, if_exists='append', index=False)\n",
    "\n",
    "            print(f\"Datos de {excel_file} cargados exitosamente a SQL Server üéØ\")\n",
    "\n",
    "            # --- Mover y renombrar el archivo ---\n",
    "            # Obtener la fecha de hoy\n",
    "            fecha_hoy = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "            # Armar el nuevo nombre\n",
    "            nombre_base, extension = os.path.splitext(excel_file)\n",
    "            nuevo_nombre = f'{nombre_base}_{fecha_hoy}{extension}'\n",
    "\n",
    "            # Ruta destino con el nuevo nombre\n",
    "            ruta_destino = os.path.join(carpeta_destino, nuevo_nombre)\n",
    "\n",
    "            # Mover y renombrar\n",
    "            shutil.move(ruta_archivo, ruta_destino)\n",
    "            print(f\"Archivo {excel_file} movido y renombrado a: {ruta_destino}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Error procesando {excel_file}: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"No se encontraron archivos Excel (.xlsx) en la carpeta. Continuando con el resto del c√≥digo.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd5003e-0bfc-4ef6-b3ad-b085b4205bb0",
   "metadata": {},
   "source": [
    "## QUERY PESOS Y DIMENSIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e11bb09-76f9-4f4c-9466-a1bda00bcce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '10.12.200.59' #ip del DB es 10.11.100.103\n",
    "database = 'Maxwarehouse'\n",
    "\n",
    "# Crear el engine usando la cadena de conexi√≥n para SQL Server con pyodbc\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Ejecutar consulta \n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "SELECT TrackingNumber, ParentSku, SalesStatusEVP, TotalSales, TotalCost FROM [DWH-MaxWarehouse].[Fact].[Sales]\n",
    "WHERE SalesOrderDateTime >= DATEADD(MONTH, -4, CAST(GETDATE() AS DATE)) \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df_ventas = pd.read_sql(query, con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f81ac7-63b0-4f84-8378-8b3d4e3ef392",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '10.12.200.59' #ip del DB es 10.11.100.103\n",
    "database = 'Maxwarehouse'\n",
    "\n",
    "# Crear el engine usando la cadena de conexi√≥n para SQL Server con pyodbc\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Ejecutar consulta \n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "WITH BOXFECHAS AS (\n",
    "    SELECT \n",
    "        TRACKING_NUMBER,\n",
    "        OrderDate,\n",
    "        WEIGHT AS WeightBox,\n",
    "        CASE WHEN LEN(DIMENSIONS) >= 5 THEN CAST(SUBSTRING(DIMENSIONS, 1, CHARINDEX('x', DIMENSIONS) - 1) AS FLOAT) ELSE 0.00 END AS DimHeightBOX,\n",
    "        CASE WHEN LEN(DIMENSIONS) >= 5 THEN CAST(SUBSTRING(DIMENSIONS, CHARINDEX('x', DIMENSIONS) + 1, CHARINDEX('x', DIMENSIONS, CHARINDEX('x', DIMENSIONS) + 1) - CHARINDEX('x', DIMENSIONS) - 1) AS FLOAT) ELSE 0.00 END AS DimLengthBOX,\n",
    "        CASE WHEN LEN(DIMENSIONS) >= 5 THEN CAST(RIGHT(DIMENSIONS, LEN(DIMENSIONS) - CHARINDEX('x', DIMENSIONS, CHARINDEX('x', DIMENSIONS) + 1)) AS FLOAT) ELSE 0.00 END AS DimWidthBOX,\n",
    "        CCN_ORDER_NUMBER\n",
    "    FROM BOX\n",
    "    WHERE ISDATE(OrderDate) = 1\n",
    "),\n",
    "\n",
    "endicia_semana_mes AS (\n",
    "    SELECT DISTINCT  \n",
    "        [Postmark_Date] AS TranDate, \n",
    "        [Transaction_Date (GMT)] AS InvDate, \n",
    "        REPLACE([Tracking Number], '''', '') AS trackingnum, \n",
    "        [Weight_(lb)], \n",
    "        [Package Height], \n",
    "        [Package Length], \n",
    "        [Package Width]\n",
    "    FROM Endiciatransacprovision\n",
    "    WHERE ISDATE([Transaction_Date (GMT)]) = 1\n",
    "      AND CAST([Transaction_Date (GMT)] AS date) >= DATEADD(MONTH, -4, GETDATE())\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT DISTINCT  \n",
    "        [Postmark Date] AS TranDate, \n",
    "        [Transaction Date (GMT)] AS InvDate, \n",
    "        REPLACE([Tracking Number], '''', '') AS trackingnum, \n",
    "        [Weight (lb)], \n",
    "        [Package Height], \n",
    "        [Package Length], \n",
    "        [Package Width]\n",
    "    FROM endicia_semanal\n",
    "    WHERE ISDATE([Transaction Date (GMT)]) = 1\n",
    "      AND CAST([Transaction Date (GMT)] AS date) >= DATEADD(MONTH, -2, GETDATE())\n",
    "),\n",
    "\n",
    "Factura3meses AS (\n",
    "\n",
    "    -- FEDEX\n",
    "    SELECT DISTINCT\n",
    "        CAST(InvoiceDate AS date) AS TranDate,\n",
    "        CAST(InvoiceDate AS date) AS InvDate,\n",
    "        GroundTrackingIDPrefix + ExpressorGroundTrackingID AS trackingnum,\n",
    "        MAX(ActualWeightAmount) AS max_weight, \n",
    "        COALESCE(NULLIF(DimHeight, ''), CAST(DimHeightBOX AS VARCHAR)) AS DimHeight,\n",
    "        COALESCE(NULLIF(DimLength, ''), CAST(DimLengthBOX AS VARCHAR)) AS DimLength,\n",
    "        COALESCE(NULLIF(DimWidth, ''), CAST(DimWidthBOX AS VARCHAR)) AS DimWidth,\n",
    "        MAX(CCN_ORDER_NUMBER) AS CCN_ORDER_NUMBER\n",
    "    FROM \n",
    "        FEDEXHISTORICO\n",
    "    LEFT JOIN \n",
    "        BOXFECHAS ON GroundTrackingIDPrefix + ExpressorGroundTrackingID = TRACKING_NUMBER\n",
    "    WHERE \n",
    "        CAST(InvoiceDate AS date) >= DATEADD(MONTH, -3, GETDATE())\n",
    "    GROUP BY \n",
    "        CAST(InvoiceDate AS date),\n",
    "        CAST(InvoiceDate AS date),\n",
    "        GroundTrackingIDPrefix + ExpressorGroundTrackingID,\n",
    "        COALESCE(NULLIF(DimHeight, ''), CAST(DimHeightBOX AS VARCHAR)),\n",
    "        COALESCE(NULLIF(DimLength, ''), CAST(DimLengthBOX AS VARCHAR)),\n",
    "        COALESCE(NULLIF(DimWidth, ''), CAST(DimWidthBOX AS VARCHAR))\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- UPS (CON PRIORIDAD PackageDimensions)\n",
    "    SELECT \n",
    "    TranDate,\n",
    "    InvDate,\n",
    "    TrackingNumber,\n",
    "    max_weight,\n",
    "    Valor1 AS DimHeight,\n",
    "    Valor2 AS DimLength,\n",
    "    Valor3 AS DimWidth,\n",
    "    CCN_ORDER_NUMBER\n",
    "\tFROM (\n",
    "    SELECT \n",
    "        CAST(u.TransactionDate AS date) AS TranDate,\n",
    "        CAST(u.InvoiceDate AS date) AS InvDate,\n",
    "        u.TrackingNumber,\n",
    "        CASE \n",
    "            WHEN u.EnteredWeight != 0 THEN u.EnteredWeight\n",
    "            WHEN u.BilledWeight IS NOT NULL AND u.BilledWeight != 0 THEN u.BilledWeight\n",
    "            ELSE b.WeightBox\n",
    "        END AS max_weight,\n",
    "        CASE \n",
    "            WHEN COALESCE(u.PackageDimensions, '') <> '' THEN CAST(SUBSTRING(u.PackageDimensions, 1, CHARINDEX('x', u.PackageDimensions) - 1) AS FLOAT)\n",
    "            WHEN LEN(u.DetailKeyedDim) >= 5 THEN CAST(SUBSTRING(u.DetailKeyedDim, 1, CHARINDEX('x', u.DetailKeyedDim) - 1) AS FLOAT)\n",
    "            ELSE b.DimHeightBOX\n",
    "        END AS Valor1,\n",
    "        CASE \n",
    "            WHEN COALESCE(u.PackageDimensions, '') <> '' THEN CAST(SUBSTRING(u.PackageDimensions, CHARINDEX('x', u.PackageDimensions) + 1, CHARINDEX('x', u.PackageDimensions, CHARINDEX('x', u.PackageDimensions) + 1) - CHARINDEX('x', u.PackageDimensions) - 1) AS FLOAT)\n",
    "            WHEN LEN(u.DetailKeyedDim) >= 5 THEN CAST(SUBSTRING(u.DetailKeyedDim, CHARINDEX('x', u.DetailKeyedDim) + 1, CHARINDEX('x', u.DetailKeyedDim, CHARINDEX('x', u.DetailKeyedDim) + 1) - CHARINDEX('x', u.DetailKeyedDim) - 1) AS FLOAT)\n",
    "            ELSE b.DimLengthBOX\n",
    "        END AS Valor2,\n",
    "        CASE \n",
    "            WHEN COALESCE(u.PackageDimensions, '') <> '' THEN CAST(RIGHT(u.PackageDimensions, LEN(u.PackageDimensions) - CHARINDEX('x', u.PackageDimensions, CHARINDEX('x', u.PackageDimensions) + 1)) AS FLOAT)\n",
    "            WHEN LEN(u.DetailKeyedDim) >= 5 THEN CAST(RIGHT(u.DetailKeyedDim, LEN(u.DetailKeyedDim) - CHARINDEX('x', u.DetailKeyedDim, CHARINDEX('x', u.DetailKeyedDim) + 1)) AS FLOAT)\n",
    "            ELSE b.DimWidthBOX\n",
    "        END AS Valor3,\n",
    "        CCN_ORDER_NUMBER,\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY u.TrackingNumber\n",
    "            ORDER BY \n",
    "                CASE \n",
    "                    WHEN COALESCE(u.PackageDimensions, '') <> '' THEN 1\n",
    "                    WHEN LEN(u.DetailKeyedDim) >= 5 THEN 2\n",
    "                    ELSE 3\n",
    "                END ASC,\n",
    "                u.InvoiceDate DESC\n",
    "        ) AS RowNum\n",
    "    FROM \n",
    "        UPSNEWFORMAT u\n",
    "    LEFT JOIN \n",
    "        BOXFECHAS b ON u.TrackingNumber = b.TRACKING_NUMBER\n",
    "    WHERE \n",
    "        CAST(u.InvoiceDate AS date) >= DATEADD(MONTH, -3, GETDATE())\n",
    "\t) AS UPSFiltrado\n",
    "\tWHERE RowNum = 1\n",
    "\n",
    "\n",
    "    UNION ALL\n",
    "\n",
    "    -- USPS (Endicia)\n",
    "    SELECT DISTINCT \n",
    "        TranDate,\n",
    "        InvDate,\n",
    "        trackingnum,\n",
    "        COALESCE([Weight_(lb)], b.WeightBox) AS max_weight,\n",
    "        COALESCE([Package Height], b.DimHeightBOX) AS DimHeight,\n",
    "        COALESCE([Package Length], b.DimLengthBOX) AS DimLength,\n",
    "        COALESCE([Package Width], b.DimWidthBOX) AS DimWidth,\n",
    "        CCN_ORDER_NUMBER\n",
    "    FROM \n",
    "        endicia_semana_mes e\n",
    "    LEFT JOIN \n",
    "        BOXFECHAS b ON b.TRACKING_NUMBER = e.trackingnum\n",
    "    WHERE \n",
    "        trackingnum IS NOT NULL\n",
    "        AND CAST(InvDate AS date) >= DATEADD(MONTH, -4, GETDATE()) -- USPS 4 meses porque vienen mensual\n",
    "),\n",
    "\n",
    "DWVentasUnicas as (\n",
    "\tSelect \n",
    "\t\tSalesOrderNumber, Sku\n",
    "\tfrom DWShippingInfo as dws\n",
    "\twhere cast(SalesOrderDate as date ) between dateadd(MONTH,-4, cast(GETDATE() as date)) and cast(GETDATE() as date)\n",
    "\tgroup by SalesOrderNumber, Sku\n",
    "),\n",
    "\n",
    "CantidadSkusxVenta as (\n",
    "\tselect\n",
    "\t\tSalesOrderNumber, count(Sku) CantidadSkus\n",
    "\tfrom DWVentasUnicas dw \n",
    "\tgroup by SalesOrderNumber\n",
    "\thaving count(Sku) =1\n",
    "),\n",
    "\n",
    "PesosfacturaVentas as (\n",
    "\t--Lista los trackings con su peso y le coloca la moda y las frecuencia con que ese peso fue facturado\n",
    "\tselect  \n",
    "\t\tTranDate, InvDate, dw.trackingnum, max_weight, DimHeight, DimLength, DimWidth, mw.Sku, mw.UomCode, mw.UomQuantity\n",
    "\tFROM Factura3meses dw\n",
    "\tINNER JOIN DWShippingInfo  mw\n",
    "\t\tON dw.trackingnum = mw.trackingnum\n",
    "\tWHERE dw.trackingnum !=''\n",
    "\tand SalesOrderNumber in (select SalesOrderNumber from CantidadSkusxVenta)\n",
    "\tand cast(UomQuantity as float)/cast(Quantity as float)= 1\n",
    "),\n",
    "\n",
    "RankedData AS (\n",
    "    SELECT \n",
    "        TranDate, \n",
    "        InvDate, \n",
    "        trackingnum, \n",
    "        Sku, \n",
    "        UomCode, \n",
    "        UomQuantity,\n",
    "        max_weight, \n",
    "        DimHeight, \n",
    "        DimLength, \n",
    "        DimWidth,\n",
    "        RANK() OVER (\n",
    "            PARTITION BY TranDate, trackingnum, Sku, UomCode \n",
    "            ORDER BY InvDate DESC\n",
    "        ) AS Ranking\n",
    "    FROM PesosfacturaVentas\n",
    "),\n",
    "\n",
    "Max_Rank as (SELECT \n",
    "    TranDate, \n",
    "    InvDate, \n",
    "    trackingnum, \n",
    "    Sku, \n",
    "    UomCode, \n",
    "    UomQuantity,\n",
    "    MAX(max_weight) AS Weight, \n",
    "    MAX(DimHeight) AS Height, \n",
    "    MAX(DimLength) AS Length, \n",
    "    MAX(DimWidth) AS Width,\n",
    "    Ranking\n",
    "FROM RankedData\n",
    "GROUP BY TranDate, InvDate, trackingnum, Sku, UomCode, UomQuantity, Ranking\n",
    "),\n",
    "\n",
    "EJD_DIMS as (SELECT aa.*, \n",
    "       bb.[EJD Weight], \n",
    "       bb.[EJD Height], \n",
    "       bb.[EJD Length], \n",
    "       bb.[EJD Width],\n",
    "       bb.[BaseUnit]\n",
    "FROM Max_Rank aa\n",
    "LEFT JOIN (\n",
    "    SELECT DISTINCT [EVP SKU], [EVP UOM CODE], [EVP UOM QTY], [EJD Weight], [EJD Height], [EJD Length], [EJD Width], [BaseUnit]\n",
    "    FROM [stg-MaxWarehouse].[EvpCsv].[EVPAlllSKUsDimNWeight]\n",
    ") bb\n",
    "ON aa.Sku COLLATE SQL_Latin1_General_CP1_CI_AS = bb.[EVP SKU] COLLATE SQL_Latin1_General_CP1_CI_AS\n",
    "and aa.UomCode COLLATE SQL_Latin1_General_CP1_CI_AS= bb.[EVP UOM CODE] COLLATE SQL_Latin1_General_CP1_CI_AS\n",
    "),\n",
    "\n",
    "Ventas as (\n",
    "    SELECT * \n",
    "    FROM [DWH-MaxWarehouse].[Fact].[Sales]\n",
    "    WHERE SalesOrderDateTime >= DATEADD(MONTH, -4, CAST(GETDATE() AS DATETIME))\n",
    "      AND SalesOrderDateTime < DATEADD(DAY, 1, CAST(GETDATE() AS DATETIME))\n",
    ")\n",
    "\n",
    "select distinct * from EJD_DIMS \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "q1 = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4928e16-fd83-4862-bfd8-88e193a4a47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(q1, df_ventas, left_on=['trackingnum', 'Sku'], right_on=['TrackingNumber', 'ParentSku'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3076e25-c35f-41a7-8c0f-77509396c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merged.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f444e16-9394-43b3-850c-8c548e7f0491",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\n",
    "    \"EJD Weight\": \"EJD_Weight\",\n",
    "    \"EJD Height\": \"EJD_Height\",\n",
    "    \"EJD Length\": \"EJD_Length\",\n",
    "    \"EJD Width\": \"EJD_Width\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b37ca-0b55-4e2e-8250-ba5aca4c1f29",
   "metadata": {},
   "source": [
    "## Limpiar UOMCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cdfe357-3ac7-4408-a9a7-b2524e9bb3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_uom_code(df, column='UomCode'):\n",
    "    \"\"\"\n",
    "    Normaliza la columna UomCode:\n",
    "    - Convierte a may√∫sculas\n",
    "    - Elimina espacios innecesarios\n",
    "    - Reemplaza valores seg√∫n las reglas definidas\n",
    "    - Convierte formatos como \"CASE_X\" ‚Üí \"CS/X\" y \"PACK OF X\" ‚Üí \"PK/X\"\n",
    "    \n",
    "    Par√°metros:\n",
    "        df (pd.DataFrame): DataFrame con la columna UomCode\n",
    "        column (str): Nombre de la columna a normalizar\n",
    "    \n",
    "    Retorna:\n",
    "        pd.DataFrame: DataFrame con una nueva columna 'UomCode_N' normalizada\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convertir a may√∫sculas y eliminar espacios innecesarios\n",
    "    df['UomCode_N'] = df[column].str.strip().str.upper()\n",
    "\n",
    "    # Reemplazar \"CASE_X\" ‚Üí \"CS/X\" antes de otros reemplazos\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^CASE[_\\s]?(\\d+)', r'CS/\\1', regex=True)\n",
    "\n",
    "    # Reemplazar caracteres no uniformes y homogenizar\n",
    "    replacements = {\n",
    "        r'\\bEACH\\b': 'EA',  # EACH ‚Üí EA\n",
    "        r'\\bEA\\b': 'EA',    # Variaciones de EA ‚Üí EA\n",
    "        r'\\bCASE\\b': 'CS',  # CASE ‚Üí CS\n",
    "        r'\\bPACK\\b': 'PK',  # PACK ‚Üí PK\n",
    "        r'_' : '/'         # Reemplazar \"_\" por \"/\"\n",
    "    }\n",
    "    \n",
    "    df['UomCode_N'] = df['UomCode_N'].replace(replacements, regex=True)\n",
    "\n",
    "    # Convertir \"PACK/X\" a \"PK/X\"\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^PACK/', 'PK/', regex=True)\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^PA/', 'PK/', regex=True)\n",
    "\n",
    "    # Convertir \"CS OF X\" ‚Üí \"CS_X\" y \"PK OF X\" ‚Üí \"PK_X\"\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^CS OF (\\d+)', r'CS/\\1', regex=True)\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^PK OF (\\d+)', r'PK/\\1', regex=True)\n",
    "\n",
    "    # Reemplazar '/' por '_'\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace('/', '_', regex=False)\n",
    "\n",
    "    # Reemplazar \"ACE\" por \"EA\" y quitar el resto de la cadena\n",
    "    df['UomCode_N'] = df['UomCode_N'].str.replace(r'^ACE.*', 'EA', regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897ae865-1353-4707-8ff9-aca4084457cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalize_uom_code(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f4321-c368-44e0-98a8-3302aae0d61a",
   "metadata": {},
   "source": [
    "## Tomar el valor m√°s reciente para pesos y dimensiones por transaccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2301f093-1449-4cdd-807e-fd5b034b45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que las fechas son tipo datetime\n",
    "df['TranDate'] = pd.to_datetime(df['TranDate'])\n",
    "df['InvDate'] = pd.to_datetime(df['InvDate'])\n",
    "\n",
    "# Ordenar primero \n",
    "df = df.sort_values(['TranDate', 'trackingnum', 'Sku', 'UomCode_N', 'InvDate'], ascending=[True, True, True, True, False])\n",
    "\n",
    "# Obtener el √≠ndice del invdate m√°s reciente dentro de cada grupo\n",
    "idx = df.groupby(['TranDate', 'trackingnum', 'Sku', 'UomCode_N'])['InvDate'].idxmax()\n",
    "\n",
    "# Seleccionar las filas correspondientes\n",
    "df_mas_reciente = df.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ad2d3b-2c8c-43d1-bb88-ef7a839f786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que las fechas son tipo datetime\n",
    "\n",
    "# Ordenar primero \n",
    "df_mas_reciente2 = df_mas_reciente.sort_values(['TranDate', 'trackingnum', 'Sku', 'UomCode_N', 'InvDate'], ascending=[False, True, True, True, True])\n",
    "\n",
    "# Obtener el √≠ndice del invdate m√°s reciente dentro de cada grupo\n",
    "idx = df_mas_reciente2.groupby(['InvDate', 'trackingnum', 'Sku', 'UomCode_N'])['TranDate'].idxmax()\n",
    "\n",
    "# Seleccionar las filas correspondientes\n",
    "df_mas_reciente2 = df_mas_reciente2.loc[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17377270-ae5c-4bb5-87fc-a5233e58f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar trackings repetidos por fechas\n",
    "\n",
    "# Ordenar y seleccionar la fila con invdate m√°s reciente para cada grupo de ['trackingnum', 'Sku', 'UomCode_N']\n",
    "idx = df_mas_reciente2.groupby(['trackingnum', 'Sku', 'UomCode_N'])['InvDate'].idxmax()\n",
    "\n",
    "# 3. Filtrar las filas\n",
    "df_mas_reciente3 = df_mas_reciente2.loc[idx].reset_index(drop=True)\n",
    "\n",
    "df = df_mas_reciente3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96ccfed1-4504-49f7-8a9f-0dfd735d21a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\179128486.py:6: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df2[cols_to_fill] = df2.groupby(['TranDate', 'trackingnum', 'Sku', 'UomCode_N'])[cols_to_fill].transform(lambda x: x.bfill())\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\179128486.py:6: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df2[cols_to_fill] = df2.groupby(['TranDate', 'trackingnum', 'Sku', 'UomCode_N'])[cols_to_fill].transform(lambda x: x.bfill())\n"
     ]
    }
   ],
   "source": [
    "df2 = df.sort_values(by=['TranDate', 'trackingnum', 'Sku', 'UomCode_N', 'InvDate'], ascending=[True, True, True, True, False])\n",
    "\n",
    "cols_to_fill = ['Weight', 'Height', 'Length', 'Width']\n",
    "df2[cols_to_fill] = df2[cols_to_fill].replace(0, pd.NA)\n",
    "\n",
    "df2[cols_to_fill] = df2.groupby(['TranDate', 'trackingnum', 'Sku', 'UomCode_N'])[cols_to_fill].transform(lambda x: x.bfill())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b967b4-a845-4d4a-9e54-087e9a37d8b4",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c2a0fa-7217-48d0-8e47-639bd7922233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar por TranDate, trackingnum, Sku, UomCode_N, y InvDate DESC\n",
    "df2 = df2.sort_values(by=['TranDate', 'trackingnum', 'Sku', 'UomCode_N', 'InvDate'], ascending=[True, True, True, True, False])\n",
    "\n",
    "# Asignar ranking dentro de cada grupo seg√∫n InvDate DESC (el primero ser√° Rank 1)\n",
    "df2['Rank'] = df2.groupby(['TranDate', 'trackingnum', 'Sku', 'UomCode_N']).cumcount() + 1\n",
    "\n",
    "# Filtrar solo los de Ranking = 1\n",
    "df_final = df2[df2['Rank'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d027d87-fb13-43d8-b1ab-96d65a41cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight con nulos relleno con la moda\n",
    "\n",
    "# Funci√≥n para obtener la moda, con manejo de m√∫ltiples modas\n",
    "def obtener_moda(grupo):\n",
    "    moda = grupo.mode()\n",
    "    if not moda.empty:\n",
    "        return moda.iloc[0]  # toma la primera si hay varias\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Calcular la moda por combinaci√≥n de Sku y UomCode_N\n",
    "moda_por_sku_uom = (\n",
    "    df_final.groupby(['Sku', 'UomCode_N'])['Weight']\n",
    "    .transform(lambda x: x.fillna(obtener_moda(x)))\n",
    ")\n",
    "\n",
    "# Reemplazar los valores nulos en Weight con la moda correspondiente\n",
    "df_final['Weight'] = df_final['Weight'].fillna(moda_por_sku_uom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d69f44b-3ad4-4249-abc0-52410c4a455e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar nulos\n",
    "\n",
    "df_final = df_final.dropna(subset=['TranDate', 'InvDate', 'trackingnum', 'Sku', 'UomCode_N', 'Weight', 'Weight', 'Length', 'Width'])\n",
    "df_final.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16a95c30-2590-4a20-9f7a-fea3e8a0c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertir tipo de dato\n",
    "\n",
    "df_final['Weight'] = df_final['Weight'].astype(str).astype(float)\n",
    "df_final['Height'] = df_final['Height'].astype(str).astype(float)\n",
    "df_final['Length'] = df_final['Length'].astype(str).astype(float)\n",
    "df_final['Width'] = df_final['Width'].astype(str).astype(float)\n",
    "df_final['EJD_Weight'] = df_final['EJD_Weight'].astype(str).astype(float)\n",
    "df_final['EJD_Length'] = df_final['EJD_Length'].astype(str).astype(float)\n",
    "df_final['EJD_Height'] = df_final['EJD_Height'].astype(str).astype(float)\n",
    "df_final['EJD_Width'] = df_final['EJD_Width'].astype(str).astype(float)\n",
    "df_final['TranDate'] = pd.to_datetime(df_final['TranDate'], format='%d-%m-%Y')\n",
    "df_final['InvDate'] = pd.to_datetime(df_final['InvDate'], format='%d-%m-%Y')\n",
    "df_final['UomQuantity'] = df_final['UomQuantity'].astype(str).astype(float).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1dfce2b-7bef-4635-bc84-cd4a8d3db6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar Dimensiones de mayor a menor\n",
    "df_sorted = df_final.copy()\n",
    "df_sorted[['Height', 'Length', 'Width']] = df_final[['Height', 'Length', 'Width']].apply(\n",
    "    lambda row: sorted(row, reverse=True), axis=1, result_type='expand')\n",
    "\n",
    "df_sorted[['EJD_Height', 'EJD_Length', 'EJD_Width']] = df_final[['EJD_Height', 'EJD_Length', 'EJD_Width']].apply(\n",
    "    lambda row: sorted(row, reverse=True), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d35ddb2f-2e5f-42cf-aa6a-d992c377e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted2 = df_sorted[['trackingnum', 'Sku', 'UomCode', 'Weight', 'Height', 'Length', 'Width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "901af412-2456-4693-993f-ed6bc26e35d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\1575963599.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sorted2.rename(columns={\n"
     ]
    }
   ],
   "source": [
    "df_sorted2.rename(columns={\n",
    "    'Weight': 'Weight_Original',\n",
    "    'Height': 'Height_Original',\n",
    "    'Length': 'Length_Original',\n",
    "    'Width': 'Width_Original'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e98c1-849d-4d18-b88c-8bdb3bd3e565",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea329b9c-0c9a-4370-b20d-44b910e24eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3628699790.py:18: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_cleaned = df_sorted.groupby(['Sku', 'UomCode_N']).apply(replace_outliers_with_nan)\n"
     ]
    }
   ],
   "source": [
    "# Funci√≥n para reemplazar outliers por NaN por Sku usando IQR\n",
    "def replace_outliers_with_nan(group):\n",
    "    Q1 = group[['Weight', 'Height', 'Length', 'Width']].quantile(0.25)\n",
    "    Q3 = group[['Weight', 'Height', 'Length', 'Width']].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    factor = 1.5\n",
    "\n",
    "    # Detectar outliers\n",
    "    is_outlier = ((group[['Weight', 'Height', 'Length', 'Width']] < (Q1 - factor * IQR)) |\n",
    "                  (group[['Weight', 'Height', 'Length', 'Width']] > (Q3 + factor * IQR)))\n",
    "\n",
    "    # Reemplazar outliers por NaN\n",
    "    group[['Weight', 'Height', 'Length', 'Width']] = group[['Weight', 'Height', 'Length', 'Width']].mask(is_outlier, np.nan)\n",
    "\n",
    "    return group\n",
    "\n",
    "# Aplicar la funci√≥n por cada Sku\n",
    "df_cleaned = df_sorted.groupby(['Sku', 'UomCode_N']).apply(replace_outliers_with_nan)\n",
    "\n",
    "# Reiniciar el √≠ndice si deseas (opcional)\n",
    "df_cleaned = df_cleaned.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "257a663d-bec8-4f98-8bea-681e961eb85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rellenar Vacios de outliers con la mediana\n",
    "df_cleaned[['Weight', 'Height', 'Length', 'Width']] = df_cleaned.groupby(['Sku', 'UomCode_N'])[['Weight', 'Height', 'Length', 'Width']].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f539ca-5396-41e7-baf3-b9f074c72420",
   "metadata": {},
   "source": [
    "## MODELO PREDICTIVO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625188e-67d1-4964-bcd4-72a3dced125f",
   "metadata": {},
   "source": [
    "### Agrupar por tipo de caja (semejanza entre dimensiones de la caja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf64a972-2034-4faa-9847-debe254389fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_cleaned.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a5a0263-5569-45e1-833f-ea3b1c1f3564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\2918129312.py:10: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: (\n"
     ]
    }
   ],
   "source": [
    "# Asegurar que dimensiones son num√©ricas\n",
    "df[['Height', 'Length', 'Width']] = df[['Height', 'Length', 'Width']].astype(float)\n",
    "\n",
    "# Definir tolerancia\n",
    "tolerancia = 2\n",
    "\n",
    "# Agrupar por SKU y UomCode y aplicar \"agrupaci√≥n por bins\"\n",
    "df['dim_group'] = (\n",
    "    df.groupby(['Sku', 'UomCode'], group_keys=False)\n",
    "      .apply(lambda g: (\n",
    "          ((g[['Height', 'Length', 'Width']] // tolerancia)\n",
    "           .astype(int)\n",
    "           .astype(str)\n",
    "           .agg('_'.join, axis=1))\n",
    "      ))\n",
    ")\n",
    "\n",
    "# Ahora convertir esas combinaciones a c√≥digos √∫nicos (grupos num√©ricos)\n",
    "df['grupo_dim'] = df.groupby(['Sku', 'UomCode', 'dim_group'], group_keys=False).ngroup()\n",
    "\n",
    "# Opcional: eliminar columna temporal\n",
    "df.drop(columns='dim_group', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1ee91-84ba-40e5-b97d-68e030a583ea",
   "metadata": {},
   "source": [
    "### Obtener el tipo de caja mas frecuente para las dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ea875c7-cdf4-428d-bb77-ba3b2fcefb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos y tomamos el m√°ximo por Sku, UomCode y grupo_dim\n",
    "dimensiones_max = df.groupby(['Sku', 'UomCode', 'grupo_dim']).agg({\n",
    "    'Height': 'max',\n",
    "    'Length': 'max',\n",
    "    'Width': 'max',\n",
    "    'Weight': 'mean',\n",
    "    'trackingnum': 'count'  # para saber cu√°ntas veces aparece ese grupo\n",
    "}).rename(columns={'trackingnum': 'n'})\n",
    "\n",
    "# Agregar columna con criterio de desempate\n",
    "dimensiones_max['criterio'] = (\n",
    "    dimensiones_max['Height'] + 2 * dimensiones_max['Length'] + 2 * dimensiones_max['Width']\n",
    ")\n",
    "\n",
    "# Ordenar por frecuencia y criterio\n",
    "dimensiones_final = (\n",
    "    dimensiones_max\n",
    "    .reset_index()\n",
    "    .sort_values(['Sku', 'UomCode', 'n', 'criterio'], ascending=[True, True, False, False])\n",
    "    .groupby(['Sku', 'UomCode'])\n",
    "    .first()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Redondear dimensiones a 0 decimales\n",
    "dimensiones_final[['Height', 'Length', 'Width']] = (\n",
    "    dimensiones_final[['Height', 'Length', 'Width']].round(0)\n",
    ")\n",
    "\n",
    "# Redondear peso a 2 decimales\n",
    "dimensiones_final['Weight'] = (dimensiones_final[ 'Weight'].round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657c920-1451-41af-81fa-ec98f40903f8",
   "metadata": {},
   "source": [
    "## Armado Bases Finales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f0d4f-d260-4623-9d78-390bf1c0d721",
   "metadata": {},
   "source": [
    "### Base Dims EJD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "202336aa-2965-4f40-b2eb-03ccab787914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supplier = df_cleaned[[\"Sku\", \"UomCode\", \"UomQuantity\", \"BaseUnit\", \"EJD_Weight\", \"EJD_Height\", \"EJD_Length\", \"EJD_Width\"]].drop_duplicates()\n",
    "df_supplier = df_supplier.groupby([\"Sku\", \"UomCode\", \"UomQuantity\", \"BaseUnit\"])[[\"EJD_Weight\", \"EJD_Height\", \"EJD_Length\", \"EJD_Width\"]].max().reset_index()\n",
    "df_supplier[\"BaseUnit\"] = df_supplier[\"BaseUnit\"].astype(str).str.lower().map({\"true\": True, \"false\": False})\n",
    "df_supplier = df_supplier.sort_values(by=\"BaseUnit\", ascending=False).drop_duplicates(subset=[\"Sku\", \"UomCode\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfb95b-0e01-495d-8b05-63bdef2f42fc",
   "metadata": {},
   "source": [
    "### Limpieza columna BaseUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c549383-adb0-4ea2-8cf7-12fdd876198d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si UomQty es 1 se toma como BaseUnit ese sku\n",
    "\n",
    "# Base predicciones\n",
    "index_bu_null = df_supplier[df_supplier[\"BaseUnit\"].isna()].index\n",
    "df_supplier.loc[index_bu_null, 'BaseUnit'] = True\n",
    "\n",
    "# Base historico\n",
    "index_bu_null = df_cleaned[df_cleaned[\"BaseUnit\"].isna()].index\n",
    "df_cleaned.loc[index_bu_null, 'BaseUnit'] = True\n",
    "\n",
    "df_supplier.loc[df_supplier[df_supplier['BaseUnit'] == True].index, 'BaseUnit'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e57b80ea-6f23-40c7-90e8-6a1440c26cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza base cleaned\n",
    "true_clean_i = df_cleaned[df_cleaned['BaseUnit'] == 'True'].index\n",
    "df_cleaned.loc[true_clean_i, 'BaseUnit'] = True\n",
    "\n",
    "false_clean_i = df_cleaned[df_cleaned['BaseUnit'] == 'False'].index\n",
    "df_cleaned.loc[false_clean_i, 'BaseUnit'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a63e51c5-65c8-4af8-84b7-c08cb83463a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_supplier_na_base = df_supplier[df_supplier[\"BaseUnit\"].isna()]\n",
    "df_cleaned_na_base = df_cleaned[df_cleaned[\"BaseUnit\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deafd43d-dc4a-4b9c-8100-9639834683dc",
   "metadata": {},
   "source": [
    "### Union con base Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9a26788-22ca-4b71-a9bb-69427627688c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_w_supplier = pd.merge(dimensiones_final, df_supplier, on=[\"Sku\", \"UomCode\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af07b987-0de0-4b9e-81cd-a6c8e065369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = final_w_supplier[final_w_supplier['BaseUnit'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a01681a-39d9-4185-ad02-4175bf8b77c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred[[\"Sku\", \"UomCode\", \"UomQuantity\", 'Weight', 'Height', 'Length', 'Width']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3bdfd-8b9a-44b8-b522-6f1a959ca401",
   "metadata": {},
   "source": [
    "### Aplicar Threshold a Predicciones (solo como alerta de control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a6d28e3-e654-4a58-946b-ba9cadd8efa9",
   "metadata": {},
   "source": [
    "Aplicar a Skus que son unidades base unicamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7d3e3dd-8f4e-435b-8903-110b8377fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_w_supplierT = final_w_supplier[final_w_supplier['BaseUnit'] == True]\n",
    "final_w_supplierF = final_w_supplier[final_w_supplier['BaseUnit'] == False]\n",
    "\n",
    "df_cleanedT = df_cleaned[df_cleaned['BaseUnit'] == True]\n",
    "df_cleanedF = df_cleaned[df_cleaned['BaseUnit'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0d7bff5-8f40-4b43-9794-9e714d06b859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_weight\"] = final_w_supplierT[\"EJD_Weight\"] + 0.31\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_height\"] = final_w_supplierT[\"EJD_Height\"] + 3\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_length\"] = final_w_supplierT[\"EJD_Length\"] + 3\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_width\"] = final_w_supplierT[\"EJD_Width\"] + 3\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_weight\"] = df_cleanedT[\"EJD_Weight\"] + 0.31\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_height\"] = df_cleanedT[\"EJD_Height\"] + 3\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_length\"] = df_cleanedT[\"EJD_Length\"] + 3\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\778330037.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_width\"] = df_cleanedT[\"EJD_Width\"] + 3\n"
     ]
    }
   ],
   "source": [
    "#### PREDICCIONES\n",
    "# Threshold para skus con peso menor a 1\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_weight\"] = final_w_supplierT[\"EJD_Weight\"] + 0.31\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_height\"] = final_w_supplierT[\"EJD_Height\"] + 3\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_length\"] = final_w_supplierT[\"EJD_Length\"] + 3\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] < 1, \"th_width\"] = final_w_supplierT[\"EJD_Width\"] + 3\n",
    "\n",
    "# Threshold para skus con peso mayor a 1\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] >= 1, \"th_weight\"] = final_w_supplierT[\"EJD_Weight\"] + 3\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] >= 1, \"th_height\"] = final_w_supplierT[\"EJD_Height\"] + 5\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] >= 1, \"th_length\"] = final_w_supplierT[\"EJD_Length\"] + 5\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] >= 1, \"th_width\"] = final_w_supplierT[\"EJD_Width\"] + 5\n",
    "\n",
    "#### HISTORICO\n",
    "# Threshold para skus con peso menor a 1\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_weight\"] = df_cleanedT[\"EJD_Weight\"] + 0.31\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_height\"] = df_cleanedT[\"EJD_Height\"] + 3\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_length\"] = df_cleanedT[\"EJD_Length\"] + 3\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] < 1, \"th_width\"] = df_cleanedT[\"EJD_Width\"] + 3\n",
    "\n",
    "# Threshold para skus con peso mayor a 1\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] >= 1, \"th_weight\"] = df_cleanedT[\"EJD_Weight\"] + 3\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] >= 1, \"th_height\"] = df_cleanedT[\"EJD_Height\"] + 5\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] >= 1, \"th_length\"] = df_cleanedT[\"EJD_Length\"] + 5\n",
    "df_cleanedT.loc[df_cleanedT[\"EJD_Weight\"] >= 1, \"th_width\"] = df_cleanedT[\"EJD_Width\"] + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f13c631c-fc28-473d-b7c5-f5eb1417de47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"Weight\"] > final_w_supplierT[\"th_weight\"], \"fail_weight\"] = 1\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT[\"Final_Weight\"] = final_w_supplierT[\"Weight\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"Height\"] > final_w_supplierT[\"th_height\"], \"fail_eight\"] = 1\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT[\"Final_Height\"] = final_w_supplierT[\"Height\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"Length\"] > final_w_supplierT[\"th_length\"], \"fail_length\"] = 1\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT[\"Final_Length\"] = final_w_supplierT[\"Length\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT.loc[final_w_supplierT[\"Width\"] > final_w_supplierT[\"th_width\"], \"fail_width\"] = 1\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3936553958.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierT[\"Final_Width\"] = final_w_supplierT[\"Width\"]\n"
     ]
    }
   ],
   "source": [
    "# Pesos y dimensiones finales (aplicando el threshold)\n",
    "\n",
    "#### Sobrepasando limite superior del rango ########\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Weight\"] > final_w_supplierT[\"th_weight\"], \"fail_weight\"] = 1\n",
    "final_w_supplierT[\"Final_Weight\"] = final_w_supplierT[\"Weight\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Height\"] > final_w_supplierT[\"th_height\"], \"fail_eight\"] = 1\n",
    "final_w_supplierT[\"Final_Height\"] = final_w_supplierT[\"Height\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Length\"] > final_w_supplierT[\"th_length\"], \"fail_length\"] = 1\n",
    "final_w_supplierT[\"Final_Length\"] = final_w_supplierT[\"Length\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Width\"] > final_w_supplierT[\"th_width\"], \"fail_width\"] = 1\n",
    "final_w_supplierT[\"Final_Width\"] = final_w_supplierT[\"Width\"]\n",
    "\n",
    "\n",
    "#### Sobrepasando limite inferior del rango ########\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Weight\"] < final_w_supplierT[\"EJD_Weight\"], \"fail_weight\"] = 1\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Height\"] < final_w_supplierT[\"EJD_Height\"], \"fail_eight\"] = 1\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Length\"] < final_w_supplierT[\"EJD_Length\"], \"fail_length\"] = 1\n",
    "final_w_supplierT.loc[final_w_supplierT[\"Width\"] < final_w_supplierT[\"EJD_Width\"], \"fail_width\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d377669-be04-4292-bd8a-b30ea134ec58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\2575437867.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierF[\"Final_Weight\"] = final_w_supplierF[\"Weight\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\2575437867.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierF[\"Final_Height\"] = final_w_supplierF[\"Height\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\2575437867.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierF[\"Final_Length\"] = final_w_supplierF[\"Length\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\2575437867.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierF[\"Final_Width\"] = final_w_supplierF[\"Width\"]\n"
     ]
    }
   ],
   "source": [
    "# Pesos y dimensiones finales (aplicando el threshold)\n",
    "\n",
    "#### Skus que no tienen dimensiones en EJD ########\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] == 0, \"fail_weight\"] = np.nan\n",
    "final_w_supplierF[\"Final_Weight\"] = final_w_supplierF[\"Weight\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] == 0, \"fail_eight\"] = np.nan\n",
    "final_w_supplierF[\"Final_Height\"] = final_w_supplierF[\"Height\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] == 0, \"fail_length\"] = np.nan\n",
    "final_w_supplierF[\"Final_Length\"] = final_w_supplierF[\"Length\"]\n",
    "\n",
    "final_w_supplierT.loc[final_w_supplierT[\"EJD_Weight\"] == 0, \"fail_width\"] = np.nan\n",
    "final_w_supplierF[\"Final_Width\"] = final_w_supplierF[\"Width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14db1b1d-6cbb-4f97-92fc-39285b22da9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\1779026084.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_w_supplierF[['EJD_Weight', 'EJD_Height', 'EJD_Length', 'EJD_Width']] = np.nan\n"
     ]
    }
   ],
   "source": [
    "# Quitando dimensiones a Skus que no son unidad base\n",
    "\n",
    "final_w_supplierF[['EJD_Weight', 'EJD_Height', 'EJD_Length', 'EJD_Width']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b08b0c5-cc48-448b-8c6a-28aedb46111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_w_supplier = pd.concat([final_w_supplierT, final_w_supplierF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88df1ee-72d6-4197-bf70-974bc9e8072a",
   "metadata": {},
   "source": [
    "### Metricas de Desviacion con la Especificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43828305-b1f5-4f9d-b1f9-ab07c573506e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\172691531.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT[\"Sum_Dim\"] = df_cleanedT[\"Height\"] + df_cleanedT[\"Length\"] + df_cleanedT[\"Width\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\172691531.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedF[\"Sum_Dim\"] = df_cleanedF[\"Height\"] + df_cleanedF[\"Length\"] + df_cleanedF[\"Width\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\172691531.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT[\"Sum_Dim_EJD_Sup\"] = df_cleanedT[\"th_height\"] + df_cleanedT[\"th_length\"] + df_cleanedT[\"th_width\"]\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\172691531.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleanedT[\"Sum_Dim_EJD_Low\"] = df_cleanedT[\"EJD_Height\"] + df_cleanedT[\"EJD_Length\"] + df_cleanedT[\"EJD_Width\"]\n"
     ]
    }
   ],
   "source": [
    "# SUMAR DIMENSIONES\n",
    "df_cleanedT[\"Sum_Dim\"] = df_cleanedT[\"Height\"] + df_cleanedT[\"Length\"] + df_cleanedT[\"Width\"]\n",
    "df_cleanedF[\"Sum_Dim\"] = df_cleanedF[\"Height\"] + df_cleanedF[\"Length\"] + df_cleanedF[\"Width\"]\n",
    "df_cleanedT[\"Sum_Dim_EJD_Sup\"] = df_cleanedT[\"th_height\"] + df_cleanedT[\"th_length\"] + df_cleanedT[\"th_width\"]\n",
    "df_cleanedT[\"Sum_Dim_EJD_Low\"] = df_cleanedT[\"EJD_Height\"] + df_cleanedT[\"EJD_Length\"] + df_cleanedT[\"EJD_Width\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "438cb4fd-ef74-42eb-9af8-649dbb4bb466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEDIANA PESO Y DIMS\n",
    "df_metricaT = df_cleanedT.groupby([\"Sku\", 'UomCode_N', 'BaseUnit'])[[\"Weight\", \"Sum_Dim\", \"EJD_Weight\", \"th_weight\", \"Sum_Dim_EJD_Low\", \"Sum_Dim_EJD_Sup\"]].median().round(2).reset_index()\n",
    "df_metricaF = df_cleanedF.groupby([\"Sku\", 'UomCode_N', 'BaseUnit'])[['Weight', \"Sum_Dim\"]].median().round(2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8d9fc43-b50f-4660-ac83-26829196f902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG PESO\n",
    "i_w_low = df_metricaT[(df_metricaT[\"Weight\"] < df_metricaT[\"EJD_Weight\"])].index\n",
    "i_w_high = df_metricaT[(df_metricaT[\"Weight\"] > df_metricaT[\"th_weight\"])].index\n",
    "\n",
    "df_metricaT[\"Weight_Flag\"] = \"Within range\"\n",
    "df_metricaT.loc[i_w_low, \"Weight_Flag\"] = \"Underweight\"\n",
    "df_metricaT.loc[i_w_high, \"Weight_Flag\"] = \"Overweight\"\n",
    "\n",
    "df_metricaF[\"Weight_Flag\"] = \"No EJD Dims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a192abe1-7e89-4ba8-859b-6711fae904f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAG DIMS\n",
    "i_w_lowD = df_metricaT[(df_metricaT[\"Sum_Dim\"] < df_metricaT[\"Sum_Dim_EJD_Low\"])].index\n",
    "i_w_highD = df_metricaT[(df_metricaT[\"Sum_Dim\"] > df_metricaT[\"Sum_Dim_EJD_Sup\"])].index\n",
    "\n",
    "df_metricaT[\"DIM_Flag\"] = \"Within range\"\n",
    "df_metricaT.loc[i_w_lowD, \"DIM_Flag\"] = \"Under\"\n",
    "df_metricaT.loc[i_w_highD, \"DIM_Flag\"] = \"Over\"\n",
    "\n",
    "df_metricaF[\"DIM_Flag\"] = \"No EJD Dims\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ace83ac3-1c9a-4e9d-a302-60ef8159a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = pd.concat([df_cleanedT, df_cleanedF], ignore_index=True)\n",
    "df_metrica = pd.concat([df_metricaT, df_metricaF], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0154824d-e6ec-4084-8d2a-b49766588a58",
   "metadata": {},
   "source": [
    "# SALIDA EVP PARA SUBIR POR MEDIO DEL UOMCODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f806a337-3e03-47cd-acd1-c63acc33261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_evp = df_pred[['Sku', 'UomCode', 'UomQuantity', 'Weight', 'Height', 'Length', 'Width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9df0085d-f924-4738-ae99-fc3502421d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han creado 4 archivos CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\anaconda3\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "fecha = datetime.today().strftime('%Y%m%d')\n",
    "\n",
    "# Suponiendo que tu DataFrame se llama df\n",
    "chunk_size = 5000  # Tama√±o de cada archivo\n",
    "chunks = np.array_split(df_pred_evp, len(df_pred_evp) // chunk_size + (1 if len(df_pred_evp) % chunk_size != 0 else 0))  # Dividir en partes\n",
    "\n",
    "# Ruta donde quieres guardar\n",
    "ruta_base = r'C:\\Users\\ecalderon\\OneDrive - BITS - Max Warehouse\\Shipping\\Weights Process'\n",
    "\n",
    "# Guardar cada chunk en un CSV dentro de la ruta especificada\n",
    "list(map(lambda x: x[1].to_csv(os.path.join(ruta_base, f\"{fecha}_df_evp_{x[0]+1}.csv\"), index=False), enumerate(chunks)))\n",
    "\n",
    "print(f\"Se han creado {len(chunks)} archivos CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168fbf8e-4d29-480c-8810-f7643e1bed9e",
   "metadata": {},
   "source": [
    "# TABLA HIST√ìRICA PREDICCIONES PARA SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a381d01-19af-41bd-9b14-fd1c4c0fcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "df_pred_evp['Fecha'] = date.today()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f9dd3e0a-beb3-4d85-97fb-6299b44177e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Error al insertar los registros: (pyodbc.IntegrityError) ('23000', \"[23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]Cannot insert duplicate key row in object 'dbo.DataPrediccionDims' with unique index 'idx_unique_sku_uom_fecha'. The duplicate key value is (ACE-1001262, EA, 2025-05-06). (2601) (SQLExecDirectW); [23000] [Microsoft][ODBC Driver 17 for SQL Server][SQL Server]The statement has been terminated. (3621)\")\n",
      "[SQL: INSERT INTO [DataPrediccionDims] ([Sku], [UomCode], [UomQuantity], [Weight], [Height], [Length], [Width], [Fecha]) VALUES (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?) ... 6582 characters truncated ... , ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?)]\n",
      "[parameters: ('ACE-1001262', 'EA', 1.0, 2.9, 10.0, 8.0, 8.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1001296', 'EA', 1.0, 2.95, 10.0, 8.0, 8.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1001320', 'EA', 1.0, 2.9, 10.0, 8.0, 8.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-10017', 'EA', 1.0, 4.68, 10.0, 8.0, 8.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1001874', 'EA', 1.0, 0.34, 11.0, 8.0, 2.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1001882', 'EA', 1.0, 0.38, 11.0, 8.0, 3.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1002047', 'EA' ... 1996 parameters truncated ... 2.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-12391', 'EA', 1.0, 2.57, 10.0, 8.0, 8.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-1239912', 'EA', 1.0, 0.1, 15.0, 8.0, 3.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-12401', 'EA', 1.0, 1.7, 6.0, 6.0, 4.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-12411', 'EA', 1.0, 3.45, 14.0, 12.0, 6.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-12425', 'EA', 1.0, 0.4, 9.0, 6.0, 2.0, datetime.datetime(2025, 5, 6, 0, 0), 'ACE-12427', 'EA', 1.0, 1.65, 10.0, 8.0, 6.0, datetime.datetime(2025, 5, 6, 0, 0))]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    }
   ],
   "source": [
    "# Datos de conexi√≥n\n",
    "servidor = '10.12.200.59'\n",
    "base_de_datos = 'Maxwarehouse'\n",
    "\n",
    "# Crear la conexi√≥n con autenticaci√≥n de Windows\n",
    "engine = create_engine(f\"mssql+pyodbc://@{servidor}/{base_de_datos}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Nombre de la tabla destino\n",
    "table_name = 'DataPrediccionDims'\n",
    "\n",
    "try:\n",
    "    # Insertar datos en la tabla, sin duplicar registros, asegurando que se mantenga el √≠ndice √∫nico\n",
    "    df_pred_evp.to_sql(table_name, con=engine, if_exists='append', index=False)\n",
    "    print(\"‚úÖ Registros insertados correctamente.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error al insertar los registros: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161369d7-c339-42f1-96a8-e5e49ea03279",
   "metadata": {},
   "source": [
    "# Ventas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6728cb93-f4bb-4a3d-92e7-69e7810ca0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ventas = df_cleaned[['TranDate', 'InvDate', 'trackingnum','Sku', 'UomCode_N', 'UomQuantity', 'SalesStatusEVP','TotalSales', 'TotalCost']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a36533f7-6c43-47b1-bfba-35503f0d2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear campos de temporalidad\n",
    "\n",
    "df_ventas[\"Year\"] = df_ventas[\"TranDate\"].dt.year\n",
    "df_ventas[\"Month\"] = df_ventas[\"TranDate\"].dt.month_name()\n",
    "df_ventas[\"YearMonth\"] = df_ventas[\"TranDate\"].dt.strftime(\"%Y-%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9f03a2c4-cb1d-4805-b765-9b449e71de87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar por A√±o-Mes y SKU, sumando las ventas\n",
    "ventas_por_mes = df_ventas.groupby([\"YearMonth\", \"Sku\", \"UomCode_N\"])[\"TotalSales\"].sum().reset_index()\n",
    "ventas_por_mes = ventas_por_mes[ventas_por_mes['TotalSales'] != 0.00]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba3cc4c1-b30e-410d-b2ca-419786bd08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocar los meses en columnas\n",
    "\n",
    "df_transposed = ventas_por_mes.pivot_table(index=[\"Sku\", 'UomCode_N'], columns=\"YearMonth\", values=\"TotalSales\", aggfunc=\"sum\").round(2).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f800f2a-b42b-4baf-a45b-c49624c3128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3470377078.py:7: FutureWarning: The default fill_method='pad' in DataFrame.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df_transposed[\"Tendencia\"] = df_transposed[ventas_cols].pct_change(axis=1).mean(axis=1, skipna=True).round(2)\n"
     ]
    }
   ],
   "source": [
    "# Calcular tendencia\n",
    "\n",
    "# Columnas de meses\n",
    "ventas_cols = df_transposed.columns[2:]\n",
    "\n",
    "# Calcular la variaci√≥n promedio mes a mes\n",
    "df_transposed[\"Tendencia\"] = df_transposed[ventas_cols].pct_change(axis=1).mean(axis=1, skipna=True).round(2)\n",
    "\n",
    "# Reemplazar NaN por 0 si no hubo ventas en ning√∫n mes\n",
    "df_transposed = df_transposed.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70a9387a-b44d-45a2-819f-f275959c5021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sku                   0\n",
       "UomCode_N             0\n",
       "BaseUnit              0\n",
       "Weight                0\n",
       "Sum_Dim               0\n",
       "EJD_Weight         3921\n",
       "th_weight          3921\n",
       "Sum_Dim_EJD_Low    3921\n",
       "Sum_Dim_EJD_Sup    3921\n",
       "Weight_Flag           0\n",
       "DIM_Flag              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrica.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa20714-45d7-4935-bdf0-c70f910eccde",
   "metadata": {},
   "source": [
    "### Unir al dataframe de Metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35bbee71-7038-4f56-a7b7-f97ec5fe3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrica = df_metrica.merge(df_transposed, on=[\"Sku\", \"UomCode_N\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ba35f-076a-4e01-876d-35e56bbd8802",
   "metadata": {},
   "source": [
    "## CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0ef525b-38e7-441d-a9a7-d777b27c50b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_base = r'C:\\Users\\ecalderon\\OneDrive - BITS - Max Warehouse\\Shipping\\Weights Process'\n",
    "\n",
    "# Guardar los otros DataFrames en la misma ruta\n",
    "final_w_supplier.to_csv(os.path.join(ruta_base, \"df_predicciones.csv\"), index=False)\n",
    "df_sorted.to_csv(os.path.join(ruta_base, \"df_historico.csv\"), index=False)\n",
    "df_metrica.to_csv(os.path.join(ruta_base, \"df_metrica.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9cb91-0a2d-48f3-abf6-be15846c66c4",
   "metadata": {},
   "source": [
    "## Query de Salida"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e442f733-d11e-42e1-a019-22f2315227d5",
   "metadata": {},
   "source": [
    "### Por tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "885bef0d-05b6-47b0-a2dc-b6b9b7af8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '10.12.200.59' #ip del DB es 10.11.100.103\n",
    "database = 'Maxwarehouse'\n",
    "\n",
    "# Crear el engine usando la cadena de conexi√≥n para SQL Server con pyodbc\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Ejecutar consulta \n",
    "\n",
    "query2 = \"\"\"\n",
    "\n",
    "WITH \n",
    "\n",
    "endicia_semana_mes AS (\n",
    "    SELECT DISTINCT  \n",
    "        [Postmark_Date] AS TranDate, \n",
    "        [Transaction_Date (GMT)] AS InvDate, \n",
    "        REPLACE([Tracking Number], '''', '') AS trackingnum, \n",
    "\t\t[Transaction_Amount] as DiscountedNetCharge\n",
    "    FROM Endiciatransacprovision\n",
    "    WHERE ISDATE([Transaction_Date (GMT)]) = 1\n",
    "      AND CAST([Transaction_Date (GMT)] AS date) >= DATEADD(MONTH, -4, GETDATE())\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT DISTINCT  \n",
    "        [Postmark Date] AS TranDate, \n",
    "        [Transaction Date (GMT)] AS InvDate, \n",
    "        REPLACE([Tracking Number], '''', '') AS trackingnum, \n",
    "\t\t[Transaction Amount] as DiscountedNetCharge\n",
    "    FROM endicia_semanal\n",
    "    WHERE ISDATE([Transaction Date (GMT)]) = 1\n",
    "      AND CAST([Transaction Date (GMT)] AS date) >= DATEADD(MONTH, -2, GETDATE())\n",
    "),\n",
    "\n",
    "Factura3meses AS (\n",
    "\n",
    "    -- FEDEX\n",
    "    SELECT DISTINCT\n",
    "        CAST(InvoiceDate AS date) AS TranDate,\n",
    "        CAST(InvoiceDate AS date) AS InvDate,\n",
    "        GroundTrackingIDPrefix + ExpressorGroundTrackingID AS trackingnum,\n",
    "        max(NetChargeAmount) as DiscountedNetCharge\n",
    "    FROM \n",
    "        FEDEXHISTORICO\n",
    "    GROUP BY \n",
    "        CAST(InvoiceDate AS date),\n",
    "        CAST(InvoiceDate AS date),\n",
    "        GroundTrackingIDPrefix + ExpressorGroundTrackingID\n",
    "\n",
    "    UNION ALL\n",
    "    -- UPS (CON PRIORIDAD PackageDimensions)\n",
    "    SELECT \n",
    "    cast(TransactionDate as date), cast(InvoiceDate as date), TrackingNumber, sum(netamount) as DiscountedNetCharge\n",
    "\tFROM UPSNEWFORMAT\n",
    "\tGROUP BY \n",
    "\tcast(TransactionDate as date), cast(InvoiceDate as date), TrackingNumber\n",
    "\n",
    "    UNION ALL\n",
    "    -- USPS (Endicia)\n",
    "    SELECT DISTINCT \n",
    "        TranDate,\n",
    "        InvDate,\n",
    "        trackingnum,\n",
    "        DiscountedNetCharge\n",
    "    FROM endicia_semana_mes\n",
    "),\n",
    "\n",
    "DWVentasUnicas as (\n",
    "\tSelect \n",
    "\t\tSalesOrderNumber, Sku\n",
    "\tfrom DWShippingInfo as dws\n",
    "\twhere cast(SalesOrderDate as date ) between dateadd(MONTH,-4, cast(GETDATE() as date)) and cast(GETDATE() as date)\n",
    "\tgroup by SalesOrderNumber, Sku\n",
    "),\n",
    "\n",
    "CantidadSkusxVenta as (\n",
    "\tselect\n",
    "\t\tSalesOrderNumber, count(Sku) CantidadSkus\n",
    "\tfrom DWVentasUnicas dw \n",
    "\tgroup by SalesOrderNumber\n",
    "\thaving count(Sku) =1\n",
    "),\n",
    "\n",
    "PesosfacturaVentas as (\n",
    "\tselect  \n",
    "\t\tTranDate, InvDate, dw.trackingnum, mw.FulfillmentOrderNumber, dw.DiscountedNetCharge, \n",
    "\t\tmw.Sku, mw.UomCode, mw.UomQuantity, mw.EstimatedShippingCost\n",
    "\tFROM Factura3meses dw\n",
    "\tINNER JOIN DWShippingInfo  mw\n",
    "\t\tON dw.trackingnum = mw.trackingnum\n",
    "\tWHERE dw.trackingnum !=''\n",
    "\tand SalesOrderNumber in (select SalesOrderNumber from CantidadSkusxVenta)\n",
    "\tand cast(UomQuantity as float)/cast(Quantity as float)= 1\n",
    ")\n",
    "\n",
    "select InvDate,trackingnum, FulfillmentOrderNumber, sum(DiscountedNetCharge) as DiscountedNetCharge, Sku, UomCode, UomQuantity, \n",
    "max(EstimatedShippingCost) as EstimatedCost  \n",
    "from PesosfacturaVentas\n",
    "group by InvDate,trackingnum, FulfillmentOrderNumber, Sku, UomCode, UomQuantity\n",
    "having InvDate >= DATEADD(WEEK, -2, GETDATE())\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "campos_salida = pd.read_sql(query2, con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c35f7bf-a3e6-4c22-82ae-072aa450dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "campos_salida = normalize_uom_code(campos_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "874e4e9b-5cc5-48c0-8d46-8474d34e64c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_salida = final_w_supplier[[\"Sku\", \"UomCode\", \"Final_Height\", \"Final_Length\", \"Final_Width\", \"Final_Weight\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4db5c5ef-c72b-4cb8-a9fa-9dd8b24f28ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "salida_evp = pd.merge(campos_salida, base_salida, on=[\"Sku\", \"UomCode\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a1e64a62-e157-42d8-aae4-fe6312738e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "salida_evp = salida_evp[['trackingnum', 'FulfillmentOrderNumber', \"Final_Height\", \"Final_Length\", \"Final_Width\", \"Final_Weight\", 'DiscountedNetCharge']]\n",
    "salida_evp.rename(columns={\"trackingnum\": \"TrackingNumber\", \n",
    "                           \"FulfillmentOrderNumber\": \"ShipperReference\",\n",
    "                           \"Final_Height\": \"PackageHeight\",\n",
    "                           \"Final_Length\": \"PackageLength\",\n",
    "                           \"Final_Width\": \"PackageWidth\",\n",
    "                           \"Final_Weight\": \"BilledWeight\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "09d62681-67cf-4334-947e-106ac279b8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#salida_evp.to_csv(\"df_evp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c22904b-9fb9-4d6a-9d18-45c389bba224",
   "metadata": {},
   "source": [
    "## Comparacion estimated vs real cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8f3f8487-647f-4a5b-a29c-36b14efcf514",
   "metadata": {},
   "outputs": [],
   "source": [
    "campos_salida.rename(columns={'DiscountedNetCharge': 'Cost'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf60c616-a42c-46c4-b41e-996f5aea3e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir tipo de dato\n",
    "campos_salida['Cost'] = pd.to_numeric(campos_salida['Cost'], errors='coerce')\n",
    "campos_salida['EstimatedCost'] = pd.to_numeric(campos_salida['EstimatedCost'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b2ebf15a-aaae-4c18-aecf-05729eaa14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variacion porcentual del costo\n",
    "campos_salida['variacion_costo'] = ((campos_salida['Cost'] - campos_salida['EstimatedCost']) / campos_salida['EstimatedCost']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "919658ee-b6b2-4326-a067-2b4da3560769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semana del reporte\n",
    "campos_salida['Semana'] = campos_salida['InvDate'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a559cbe2-631c-465b-a89f-50e8f022acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvDate</th>\n",
       "      <th>trackingnum</th>\n",
       "      <th>FulfillmentOrderNumber</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Sku</th>\n",
       "      <th>UomCode</th>\n",
       "      <th>UomQuantity</th>\n",
       "      <th>EstimatedCost</th>\n",
       "      <th>UomCode_N</th>\n",
       "      <th>variacion_costo</th>\n",
       "      <th>Semana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38109</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1ZC6583AYW50316837</td>\n",
       "      <td>PO-259261721-EJD</td>\n",
       "      <td>-15.23</td>\n",
       "      <td>EJD-2015165</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.00</td>\n",
       "      <td>EA</td>\n",
       "      <td>-3.18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26305</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53E7A90300923856</td>\n",
       "      <td>PO-259290138-EJD</td>\n",
       "      <td>-64.38</td>\n",
       "      <td>EJD-8093917</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>33.49</td>\n",
       "      <td>EA</td>\n",
       "      <td>-2.92</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34807</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53FA660350545814</td>\n",
       "      <td>PO-259292573-EJD</td>\n",
       "      <td>-15.71</td>\n",
       "      <td>EJD-7817018</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.37</td>\n",
       "      <td>EA</td>\n",
       "      <td>-2.68</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13907</th>\n",
       "      <td>2025-04-26 00:00:00.000</td>\n",
       "      <td>1Z53FA660300539451</td>\n",
       "      <td>PO-259253057-EJD</td>\n",
       "      <td>-15.73</td>\n",
       "      <td>JEN-9001-0521</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.37</td>\n",
       "      <td>EA</td>\n",
       "      <td>-2.68</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11888</th>\n",
       "      <td>2025-04-26 00:00:00.000</td>\n",
       "      <td>1Z53FA370300919729</td>\n",
       "      <td>PO-259262631-EJD</td>\n",
       "      <td>-15.73</td>\n",
       "      <td>JEN-1400-7439</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.79</td>\n",
       "      <td>EA</td>\n",
       "      <td>-2.61</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34777</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53FA660300558743</td>\n",
       "      <td>PO-259311688-EJD</td>\n",
       "      <td>9.42</td>\n",
       "      <td>ACE-41142</td>\n",
       "      <td>PACK_12</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>9.49</td>\n",
       "      <td>PK_12</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29654</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53E8A60350814026</td>\n",
       "      <td>PO-259315370-EJD</td>\n",
       "      <td>9.25</td>\n",
       "      <td>ACE-7284037</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.37</td>\n",
       "      <td>EA</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24017</th>\n",
       "      <td>2025-05-01 01:49:07.730</td>\n",
       "      <td>9400111899560755207201</td>\n",
       "      <td>PO-259326890-EJD</td>\n",
       "      <td>5.49</td>\n",
       "      <td>ACE-22680</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>5.53</td>\n",
       "      <td>EA</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32792</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53E9290300426836</td>\n",
       "      <td>PO-259325982-EJD</td>\n",
       "      <td>9.25</td>\n",
       "      <td>ACE-7284037</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>9.37</td>\n",
       "      <td>EA</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35540</th>\n",
       "      <td>2025-05-03 00:00:00.000</td>\n",
       "      <td>1Z53FA66YW00545802</td>\n",
       "      <td>PO-259269248-EJD</td>\n",
       "      <td>7.40</td>\n",
       "      <td>ACE-6232441</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>7.46</td>\n",
       "      <td>EA</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25072 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      InvDate             trackingnum FulfillmentOrderNumber  \\\n",
       "38109 2025-05-03 00:00:00.000      1ZC6583AYW50316837       PO-259261721-EJD   \n",
       "26305 2025-05-03 00:00:00.000      1Z53E7A90300923856       PO-259290138-EJD   \n",
       "34807 2025-05-03 00:00:00.000      1Z53FA660350545814       PO-259292573-EJD   \n",
       "13907 2025-04-26 00:00:00.000      1Z53FA660300539451       PO-259253057-EJD   \n",
       "11888 2025-04-26 00:00:00.000      1Z53FA370300919729       PO-259262631-EJD   \n",
       "...                       ...                     ...                    ...   \n",
       "34777 2025-05-03 00:00:00.000      1Z53FA660300558743       PO-259311688-EJD   \n",
       "29654 2025-05-03 00:00:00.000      1Z53E8A60350814026       PO-259315370-EJD   \n",
       "24017 2025-05-01 01:49:07.730  9400111899560755207201       PO-259326890-EJD   \n",
       "32792 2025-05-03 00:00:00.000      1Z53E9290300426836       PO-259325982-EJD   \n",
       "35540 2025-05-03 00:00:00.000      1Z53FA66YW00545802       PO-259269248-EJD   \n",
       "\n",
       "        Cost            Sku  UomCode UomQuantity  EstimatedCost UomCode_N  \\\n",
       "38109 -15.23    EJD-2015165       EA     1.00000           7.00        EA   \n",
       "26305 -64.38    EJD-8093917       EA     1.00000          33.49        EA   \n",
       "34807 -15.71    EJD-7817018       EA     1.00000           9.37        EA   \n",
       "13907 -15.73  JEN-9001-0521       EA     1.00000           9.37        EA   \n",
       "11888 -15.73  JEN-1400-7439       EA     1.00000           9.79        EA   \n",
       "...      ...            ...      ...         ...            ...       ...   \n",
       "34777   9.42      ACE-41142  PACK_12    12.00000           9.49     PK_12   \n",
       "29654   9.25    ACE-7284037       EA     1.00000           9.37        EA   \n",
       "24017   5.49      ACE-22680       EA     1.00000           5.53        EA   \n",
       "32792   9.25    ACE-7284037       EA     1.00000           9.37        EA   \n",
       "35540   7.40    ACE-6232441       EA     1.00000           7.46        EA   \n",
       "\n",
       "       variacion_costo  Semana  \n",
       "38109            -3.18      18  \n",
       "26305            -2.92      18  \n",
       "34807            -2.68      18  \n",
       "13907            -2.68      17  \n",
       "11888            -2.61      17  \n",
       "...                ...     ...  \n",
       "34777            -0.01      18  \n",
       "29654            -0.01      18  \n",
       "24017            -0.01      18  \n",
       "32792            -0.01      18  \n",
       "35540            -0.01      18  \n",
       "\n",
       "[25072 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "campos_salida[(campos_salida['variacion_costo'] < 0) & (campos_salida['EstimatedCost'] != 0)].sort_values('variacion_costo', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d6c9e5b5-3f08-4cad-9ac7-1492be73a1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta completa al archivo costos.csv\n",
    "ruta_costos = os.path.join(ruta_base, 'costos.csv')\n",
    "\n",
    "# Guardar en la ruta especificada (modo append)\n",
    "campos_salida.to_csv(ruta_costos, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560cb373-966b-40e8-a8ae-f156e885b456",
   "metadata": {},
   "source": [
    "## Cuantificaci√≥n Impacto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "341d2cbc-746d-4033-b90e-00b9bcc1a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = '10.12.200.59' #ip del DB es 10.11.100.103\n",
    "database = 'Maxwarehouse'\n",
    "\n",
    "# Crear el engine usando la cadena de conexi√≥n para SQL Server con pyodbc\n",
    "engine = create_engine(f\"mssql+pyodbc://@{server}/{database}?trusted_connection=yes&driver=ODBC+Driver+17+for+SQL+Server\")\n",
    "\n",
    "# Ejecutar consulta \n",
    "\n",
    "query = \"\"\"\n",
    "select * from [stg-MaxWarehouse].[EvpCsv].[EVPAlllSKUsDimNWeight]\n",
    "\"\"\"\n",
    "\n",
    "df_evp = pd.read_sql(query, con=engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1ea16c-36c6-4c8e-b168-66c5514a5732",
   "metadata": {},
   "source": [
    "### Skus que cambiaron sus dimensiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d8113fca-ec0e-449a-b24c-e2caa725b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evp = df_evp[['EVP SKU', 'EVP UOM CODE', 'EVP UOM QTY', 'EVP Weight', 'EVP Height', 'EVP Length', 'EVP Width']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "365fe423-8086-4507-9376-00c43e9bd8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = df_pred.merge(\n",
    "    df_evp,  \n",
    "    left_on=['Sku', 'UomCode'], \n",
    "    right_on=['EVP SKU', 'EVP UOM CODE'], \n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c69b3aa0-8b69-48fe-8392-579eef2833a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVP solo toma sku base unit\n",
    "#df_bu = df_merge[df_merge['BaseUnit'] == True]\n",
    "\n",
    "# Quitando nulos\n",
    "df_bu = df_merge[~df_merge['EVP Width'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e914a673-b119-463e-a5c0-250f61c162e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3433237752.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['EVP Weight'] = pd.to_numeric(df_bu['EVP Weight'], errors='coerce')\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3433237752.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['EVP Height'] = pd.to_numeric(df_bu['EVP Height'], errors='coerce')\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3433237752.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['EVP Length'] = pd.to_numeric(df_bu['EVP Length'], errors='coerce')\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\3433237752.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['EVP Width'] = pd.to_numeric(df_bu['EVP Width'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# convertir tipo de dato\n",
    "df_bu['EVP Weight'] = pd.to_numeric(df_bu['EVP Weight'], errors='coerce')\n",
    "df_bu['EVP Height'] = pd.to_numeric(df_bu['EVP Height'], errors='coerce')\n",
    "df_bu['EVP Length'] = pd.to_numeric(df_bu['EVP Length'], errors='coerce')\n",
    "df_bu['EVP Width'] = pd.to_numeric(df_bu['EVP Width'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fbc616ef-93c9-4ce3-b6bd-7f701e5edbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\1692906994.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['Fecha'] = pd.to_datetime('today').normalize()\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\1692906994.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['Semana'] = df_bu['Fecha'].dt.isocalendar().week\n"
     ]
    }
   ],
   "source": [
    "# Fecha del reporte\n",
    "df_bu['Fecha'] = pd.to_datetime('today').normalize()\n",
    "df_bu['Semana'] = df_bu['Fecha'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9edd04f7-b805-4e36-b3d6-69988645be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\436886150.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['Sum_Dims_Pred'] = df_bu['Height'] + df_bu['Length'] + df_bu['Width']\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\436886150.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['Sum_Dims_EVP'] = df_bu['EVP Height'] + df_bu['EVP Length'] + df_bu['EVP Width']\n"
     ]
    }
   ],
   "source": [
    "# Suma dimensiones\n",
    "df_bu['Sum_Dims_Pred'] = df_bu['Height'] + df_bu['Length'] + df_bu['Width']\n",
    "df_bu['Sum_Dims_EVP'] = df_bu['EVP Height'] + df_bu['EVP Length'] + df_bu['EVP Width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "680267b6-573c-4c04-b172-ba2991637ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\34305253.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['variacion_weight'] = ((df_bu['Weight'] - df_bu['EVP Weight']) / df_bu['EVP Weight']).round(2)\n",
      "C:\\Users\\ecalderon\\AppData\\Local\\Temp\\ipykernel_29804\\34305253.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bu['variacion_dims'] = ((df_bu['Sum_Dims_Pred'] - df_bu['Sum_Dims_EVP']) / df_bu['Sum_Dims_EVP']).round(2)\n"
     ]
    }
   ],
   "source": [
    "# Variacion porcentual\n",
    "df_bu['variacion_weight'] = ((df_bu['Weight'] - df_bu['EVP Weight']) / df_bu['EVP Weight']).round(2)\n",
    "df_bu['variacion_dims'] = ((df_bu['Sum_Dims_Pred'] - df_bu['Sum_Dims_EVP']) / df_bu['Sum_Dims_EVP']).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9207579a-8d62-46d6-a132-b02715d037d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bu = df_bu.rename(columns={'EVP Weight': 'EVP_Weight', 'EVP Height': 'EVP_Height', 'EVP Length': 'EVP_Length', 'EVP Width': 'EVP_Width'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b462629d-4183-438f-a4f7-103d2ac694ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta completa al archivo\n",
    "ruta_cuantificacion = os.path.join(ruta_base, 'cuantificacion_skus.csv')\n",
    "\n",
    "# Guardar en la ruta especificada (modo append)\n",
    "df_bu.to_csv(ruta_cuantificacion, mode='a', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5996fd5-4e49-4cd9-859b-3e2bca86ee23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sku</th>\n",
       "      <th>UomCode</th>\n",
       "      <th>UomQuantity</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Length</th>\n",
       "      <th>Width</th>\n",
       "      <th>EVP SKU</th>\n",
       "      <th>EVP UOM CODE</th>\n",
       "      <th>EVP UOM QTY</th>\n",
       "      <th>EVP_Weight</th>\n",
       "      <th>EVP_Height</th>\n",
       "      <th>EVP_Length</th>\n",
       "      <th>EVP_Width</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Semana</th>\n",
       "      <th>Sum_Dims_Pred</th>\n",
       "      <th>Sum_Dims_EVP</th>\n",
       "      <th>variacion_weight</th>\n",
       "      <th>variacion_dims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACE-1001262</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ACE-1001262</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.340</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.350</td>\n",
       "      <td>4.350</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.700</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACE-1001296</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ACE-1001296</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.525</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.400</td>\n",
       "      <td>4.400</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.800</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACE-1001320</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ACE-1001320</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.360</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.300</td>\n",
       "      <td>4.350</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.650</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACE-10017</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.68</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>ACE-10017</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.100</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.150</td>\n",
       "      <td>4.150</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>26.0</td>\n",
       "      <td>13.250</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACE-1001874</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ACE-1001874</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.700</td>\n",
       "      <td>3.950</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.800</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16027</th>\n",
       "      <td>STC-BTU25X20RWHH</td>\n",
       "      <td>EACH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.00</td>\n",
       "      <td>33.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STC-BTU25X20RWHH</td>\n",
       "      <td>EACH</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>11.000</td>\n",
       "      <td>33.00</td>\n",
       "      <td>24.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16028</th>\n",
       "      <td>STC-BTU8X4SWHH</td>\n",
       "      <td>EACH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>STC-BTU8X4SWHH</td>\n",
       "      <td>EACH</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.600</td>\n",
       "      <td>14.00</td>\n",
       "      <td>7.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16029</th>\n",
       "      <td>TSM-MDN7020</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>TSM-MDN7020</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>16.40</td>\n",
       "      <td>9.200</td>\n",
       "      <td>16.100</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>42.0</td>\n",
       "      <td>41.700</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16030</th>\n",
       "      <td>TSM-MDN7020-A</td>\n",
       "      <td>PACK_1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.67</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>TSM-MDN7020-A</td>\n",
       "      <td>PACK_1</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>17.00</td>\n",
       "      <td>16.000</td>\n",
       "      <td>16.000</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.000</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16031</th>\n",
       "      <td>TSM-MYB0507BG</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TSM-MYB0507BG</td>\n",
       "      <td>EA</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.369</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.151</td>\n",
       "      <td>5.908</td>\n",
       "      <td>2025-05-06</td>\n",
       "      <td>19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10.059</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15922 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Sku UomCode  UomQuantity  Weight  Height  Length  Width  \\\n",
       "0           ACE-1001262      EA          1.0    2.90    10.0     8.0    8.0   \n",
       "1           ACE-1001296      EA          1.0    2.95    10.0     8.0    8.0   \n",
       "2           ACE-1001320      EA          1.0    2.90    10.0     8.0    8.0   \n",
       "3             ACE-10017      EA          1.0    4.68    10.0     8.0    8.0   \n",
       "4           ACE-1001874      EA          1.0    0.34    11.0     8.0    2.0   \n",
       "...                 ...     ...          ...     ...     ...     ...    ...   \n",
       "16027  STC-BTU25X20RWHH    EACH          1.0   11.00    33.0    24.0    3.0   \n",
       "16028    STC-BTU8X4SWHH    EACH          1.0    2.60    14.0     7.0    4.0   \n",
       "16029       TSM-MDN7020      EA          1.0    6.00    16.0    16.0   10.0   \n",
       "16030     TSM-MDN7020-A  PACK_1          1.0    5.67    17.0    16.0   16.0   \n",
       "16031     TSM-MYB0507BG      EA          1.0    0.20     9.0     7.0    2.0   \n",
       "\n",
       "                EVP SKU EVP UOM CODE EVP UOM QTY  EVP_Weight  EVP_Height  \\\n",
       "0           ACE-1001262           EA     1.00000       2.340        5.00   \n",
       "1           ACE-1001296           EA     1.00000       2.525        5.00   \n",
       "2           ACE-1001320           EA     1.00000       2.360        5.00   \n",
       "3             ACE-10017           EA     1.00000       2.100        4.95   \n",
       "4           ACE-1001874           EA     1.00000       0.210        8.15   \n",
       "...                 ...          ...         ...         ...         ...   \n",
       "16027  STC-BTU25X20RWHH         EACH     1.00000      11.000       33.00   \n",
       "16028    STC-BTU8X4SWHH         EACH     1.00000       2.600       14.00   \n",
       "16029       TSM-MDN7020           EA     1.00000       4.500       16.40   \n",
       "16030     TSM-MDN7020-A       PACK_1     1.00000      23.000       17.00   \n",
       "16031     TSM-MYB0507BG           EA     1.00000       0.369        1.00   \n",
       "\n",
       "       EVP_Length  EVP_Width      Fecha  Semana  Sum_Dims_Pred  Sum_Dims_EVP  \\\n",
       "0           4.350      4.350 2025-05-06      19           26.0        13.700   \n",
       "1           4.400      4.400 2025-05-06      19           26.0        13.800   \n",
       "2           4.300      4.350 2025-05-06      19           26.0        13.650   \n",
       "3           4.150      4.150 2025-05-06      19           26.0        13.250   \n",
       "4           0.700      3.950 2025-05-06      19           21.0        12.800   \n",
       "...           ...        ...        ...     ...            ...           ...   \n",
       "16027      24.000      3.000 2025-05-06      19           60.0        60.000   \n",
       "16028       7.000      4.000 2025-05-06      19           25.0        25.000   \n",
       "16029       9.200     16.100 2025-05-06      19           42.0        41.700   \n",
       "16030      16.000     16.000 2025-05-06      19           49.0        49.000   \n",
       "16031       3.151      5.908 2025-05-06      19           18.0        10.059   \n",
       "\n",
       "       variacion_weight  variacion_dims  \n",
       "0                  0.24            0.90  \n",
       "1                  0.17            0.88  \n",
       "2                  0.23            0.90  \n",
       "3                  1.23            0.96  \n",
       "4                  0.62            0.64  \n",
       "...                 ...             ...  \n",
       "16027              0.00            0.00  \n",
       "16028              0.00            0.00  \n",
       "16029              0.33            0.01  \n",
       "16030             -0.75            0.00  \n",
       "16031             -0.46            0.79  \n",
       "\n",
       "[15922 rows x 20 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6198d158-29d3-40de-be71-0c5cc57ed90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Correo enviado correctamente\n"
     ]
    }
   ],
   "source": [
    "def send_email_final():\n",
    "    # Configuraci√≥n del correo\n",
    "    sender_email = \"ecalderon@maxwarehouse.com\"  \n",
    "    sender_password = \"Maxwarehouse2025$\"  \n",
    "\n",
    "    # üîπ Lista de destinatarios\n",
    "    recipient_list = [\"ecalderon@maxwarehouse.com\", \"vpverbena@maxwarehouse.com\"]\n",
    "    \n",
    "    # Contenido del correo\n",
    "    subject = \"üîî Alerta: Generaci√≥n de predicciones de pesos completada\"\n",
    "    body = \"El modelo de predicci√≥n ha finalizado correctamente. Sube los resultados a EVP.\"\n",
    "\n",
    "    # Crear el mensaje\n",
    "    msg = MIMEText(body)\n",
    "    msg[\"Subject\"] = subject\n",
    "    msg[\"From\"] = sender_email\n",
    "    msg[\"To\"] = \", \".join(recipient_list)\n",
    "\n",
    "    try:\n",
    "        # Conectar al servidor SMTP (ejemplo para Gmail)\n",
    "        server = smtplib.SMTP(\"smtp.office365.com\", 587)  # Usa \"smtp.office365.com\" para Outlook\n",
    "        server.starttls()  # Seguridad TLS\n",
    "        server.login(sender_email, sender_password)  # Autenticaci√≥n\n",
    "        server.sendmail(sender_email, recipient_list, msg.as_string())  # Enviar\n",
    "        server.quit()\n",
    "        print(\"‚úÖ Correo enviado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† Error al enviar el correo: {e}\")\n",
    "\n",
    "# Llamar a la funci√≥n al final del proceso\n",
    "send_email_final()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afc66668-cef5-459e-9629-6e8d3da198db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "# Cargar el notebook\n",
    "with open(\"Scrip_Pesos_y_Dims_Modas_Limpio.ipynb\", \"r\", encoding=\"utf-8\") as f:\n",
    "    notebook = nbformat.read(f, as_version=4)\n",
    "\n",
    "# Extraer el c√≥digo de cada celda y guardarlo en un archivo .py\n",
    "codigo = \"\\n\".join(cell[\"source\"] for cell in notebook[\"cells\"] if cell[\"cell_type\"] == \"code\")\n",
    "\n",
    "# Guardar como .py\n",
    "with open(\"Scrip_Pesos_y_Dims_Modas.py\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(codigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97432f63-e4a6-490b-ad9a-a2366cee0d81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
